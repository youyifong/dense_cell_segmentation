{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "330e05e3",
   "metadata": {},
   "source": [
    "**Further train DeepCell Models with K's Data and Make Predictions**<br>\n",
    "The model has three heads: inner distance, outer distance, and fgbg. It works on tensorflow 2.7.1.<br>\n",
    "We first train a model with nucleus data from the Tissuenet V1.0 dataset and save the model. We then further train the model \n",
    "Training can also be done via deepcell.training.train_model_sample, which allows arbitrary size images and uses window_size to control patch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a72e9c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'tn1.0_nuclear_20221102.h5' # the model trained with nucleus data from the Tissuenet V1.0 dataset\n",
    "epochs=2 # to train with tissuenet data. about xx epochs/hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05468ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1\n"
     ]
    }
   ],
   "source": [
    "import syotil\n",
    "\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from timeit import default_timer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.losses import MSE\n",
    "\n",
    "import deepcell\n",
    "from deepcell.utils.train_utils import rate_scheduler, get_callbacks, count_gpus\n",
    "from deepcell.losses import weighted_categorical_crossentropy\n",
    "from deepcell.model_zoo.panopticnet import PanopticNet\n",
    "from deepcell_toolbox.deep_watershed import deep_watershed\n",
    "from deepcell import image_generators\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "938b06af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "FILENAMES = glob.glob(\"images/training_512x512/*_img.png\")\n",
    "print(len(FILENAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e38d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "APs={}\n",
    "for CURR_IM_NAME in FILENAMES:\n",
    "    im0 = io.imread(os.path.join(INPUT_PATH, CURR_IM_NAME))\n",
    "    mask_true=io.imread(os.path.join(INPUT_PATH, CURR_IM_NAME.replace(\"img\",\"masks\")))\n",
    "\n",
    "    x = np.expand_dims(im0, axis=-1)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    y, tile_info = app._tile_input(x)\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    print(tile_info)\n",
    "    pred = app.predict(y, image_mpp=1)\n",
    "    prd = app._untile_output(pred, tile_info)\n",
    "    #io.imshow(prd[0,:,:,0])\n",
    "    plt.show()\n",
    "    \n",
    "    APs[CURR_IM_NAME] = syotil.csi(mask_true, prd[0,:,:,0])# masks may lose one pixel if dimension is odd pixels\n",
    "\n",
    "APs[\"mAP\"]=np.mean(list(APs.values()))\n",
    "print(APs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d0c5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "seed = 0 \n",
    "n=train_X.shape[0]\n",
    "\n",
    "min_objects = 2\n",
    "\n",
    "val_size = 0.2 # fraction of data saved as validation\n",
    "\n",
    "import random\n",
    "tmp = random.sample(range(n), int(val_size*n))\n",
    "\n",
    "X_val = np.expand_dims(train_X[tmp,:,:,idx_X], axis=-1)\n",
    "y_val = np.expand_dims(train_y[tmp,:,:,idx_y], axis=-1)\n",
    "\n",
    "tmp1 = list(set(range(n)).difference (set(tmp)))\n",
    "X_train = np.expand_dims(train_X[tmp1,:,:,idx_X], axis=-1)\n",
    "y_train = np.expand_dims(train_y[tmp1,:,:,idx_y], axis=-1)\n",
    "\n",
    "print('X_train.shape: {}\\nX_val.shape: {}'.format(\n",
    "    X_train.shape, X_val.shape))\n",
    "transforms = ['inner-distance', 'outer-distance', 'fgbg']\n",
    "transforms_kwargs = {'outer-distance': {'erosion_width': 0}}\n",
    "\n",
    "# use augmentation for training but not validation\n",
    "datagen = image_generators.SemanticDataGenerator(\n",
    "    rotation_range=180,\n",
    "    fill_mode='reflect',\n",
    "    zoom_range=(0.75, 1.25),\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "\n",
    "datagen_val = image_generators.SemanticDataGenerator()\n",
    "\n",
    "batch_size = 4 # 8 causes memory outage\n",
    "\n",
    "train_data = datagen.flow(\n",
    "    {'X': X_train, 'y': y_train},\n",
    "    seed=seed,\n",
    "    transforms=transforms,\n",
    "    transforms_kwargs=transforms_kwargs,\n",
    "    min_objects=min_objects,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_data = datagen_val.flow(\n",
    "    {'X': X_val, 'y': y_val},\n",
    "    seed=seed,\n",
    "    transforms=transforms,\n",
    "    transforms_kwargs=transforms_kwargs,\n",
    "    min_objects=min_objects,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "# get number of training and validation instances\n",
    "\n",
    "cnts_train = [np.max(y_train[i,...]) for i in range(y_train.shape[0])]\n",
    "print(np.sum(cnts_train)) # total number of training instances\n",
    "\n",
    "cnts_val = [np.max(y_val[i,...]) for i in range(y_val.shape[0])]\n",
    "print(np.sum(cnts_val)) # total number of validation instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b79383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=5\n",
    "plt.subplot(1, 2, 1) # row 1, col 2 index 1\n",
    "io.imshow(X_train[i,:,:,0])\n",
    "plt.subplot(1, 2, 2) # row 1, col 2 index 1\n",
    "# tmp = syotil.masks_to_outlines(y_train[i,:,:,0]); io.imshow(tmp)\n",
    "io.imshow(y_train[i,:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9591736f",
   "metadata": {},
   "source": [
    "**The two cells below define and train the model.** They can be skipped if a trained model will be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebc07f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_classes = [1, 1, 2] # inner distance, outer distance, fgbg\n",
    "\n",
    "model = PanopticNet(\n",
    "    backbone='resnet50',\n",
    "    input_shape=X_train.shape[1:],\n",
    "    norm_method='whole_image',\n",
    "    num_semantic_classes=semantic_classes)\n",
    "\n",
    "lr = 1e-4\n",
    "optimizer = Adam(lr=lr, clipnorm=0.001)\n",
    "lr_sched = rate_scheduler(lr=lr, decay=0.99)\n",
    "\n",
    "# Create a dictionary of losses for each semantic head\n",
    "\n",
    "def semantic_loss(n_classes):\n",
    "    def _semantic_loss(y_pred, y_true):\n",
    "        if n_classes > 1:\n",
    "            return 0.01 * weighted_categorical_crossentropy(\n",
    "                y_pred, y_true, n_classes=n_classes)\n",
    "        return MSE(y_pred, y_true)\n",
    "    return _semantic_loss\n",
    "\n",
    "loss = {}\n",
    "\n",
    "# Give losses for all of the semantic heads\n",
    "for layer in model.layers:\n",
    "    if layer.name.startswith('semantic_'):\n",
    "        n_classes = layer.output_shape[-1]\n",
    "        loss[layer.name] = semantic_loss(n_classes)\n",
    "        \n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "[(layer.name, layer.output_shape) for layer in filter(lambda x: x.name.startswith('semantic_'), model.layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fab4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "print('Training on', count_gpus(), 'GPUs.')\n",
    "\n",
    "train_callbacks = get_callbacks(\n",
    "    model_path,\n",
    "    lr_sched=lr_sched,\n",
    "    monitor='val_loss',\n",
    "    verbose=1)\n",
    "\n",
    "loss_history = model.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=train_data.y.shape[0] // batch_size,\n",
    "    epochs=epochs, \n",
    "    validation_data=val_data,\n",
    "    validation_steps=val_data.y.shape[0] // batch_size,\n",
    "    callbacks=train_callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f3f44b",
   "metadata": {},
   "source": [
    "<B>Make predictions on Nuclear test dataset.</B> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf36df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_model = PanopticNet(\n",
    "    backbone='resnet50',\n",
    "    norm_method='whole_image',\n",
    "    num_semantic_classes=[1, 1], # inner distance, outer distance\n",
    "    input_shape= X_val.shape[1:]\n",
    ")\n",
    "\n",
    "prediction_model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bdf527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on validation data\n",
    "\n",
    "# insufficient memory error!\n",
    "\n",
    "start = default_timer()\n",
    "test_images = prediction_model.predict(X_val)\n",
    "watershed_time = default_timer() - start\n",
    "\n",
    "# print('Watershed segmentation of shape', test_images[0].shape, 'in', watershed_time, 'seconds.')\n",
    "\n",
    "masks = deep_watershed(\n",
    "    test_images,\n",
    "    min_distance=10,\n",
    "    detection_threshold=0.1,\n",
    "    distance_threshold=0.01,\n",
    "    exclude_border=False,\n",
    "    small_objects_threshold=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d476b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imshow(X_val[1,:,:,0])\n",
    "plt.show()\n",
    "io.imshow(y_val[1,:,:,0])\n",
    "plt.show()\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70549c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "APs = [syotil.csi(y_val[i,:,:,0], masks[i,:,:,0]) for i in range(y_val.shape[0])]\n",
    "print(np.nanmean(APs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42277d43",
   "metadata": {},
   "source": [
    "**Make prediction on K's data.**<br>\n",
    "Using NuclearSegmentation allows setting image_mpp, which has a substantial influence on performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a766dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell.applications import NuclearSegmentation\n",
    "app = NuclearSegmentation(prediction_model)\n",
    "[(layer.name, layer.output_shape) for layer in filter(lambda x: x.name.startswith('semantic_'), app.model.layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20301e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "INPUT_PATH=\"images/test/\"\n",
    "FILENAMES = [f for f in os.listdir(\"images/training/testimages\")]\n",
    "print(FILENAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31fa740",
   "metadata": {},
   "outputs": [],
   "source": [
    "APs={}\n",
    "for CURR_IM_NAME in FILENAMES:\n",
    "    im0 = io.imread(os.path.join(INPUT_PATH, CURR_IM_NAME))\n",
    "    mask_true=io.imread(os.path.join(INPUT_PATH, CURR_IM_NAME.replace(\"img\",\"masks\")))\n",
    "\n",
    "    x = np.expand_dims(im0, axis=-1)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    y, tile_info = app._tile_input(x)\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    print(tile_info)\n",
    "    pred = app.predict(y, image_mpp=1)\n",
    "    prd = app._untile_output(pred, tile_info)\n",
    "    #io.imshow(prd[0,:,:,0])\n",
    "    plt.show()\n",
    "    \n",
    "    APs[CURR_IM_NAME] = syotil.csi(mask_true, prd[0,:,:,0])# masks may lose one pixel if dimension is odd pixels\n",
    "\n",
    "APs[\"mAP\"]=np.mean(list(APs.values()))\n",
    "print(APs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc06419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([FILENAMES+[\"mAP\"], list(APs.values())])\n",
    "print(df.transpose())\n",
    "df.to_csv('images/training/csi_tn_'+label+'.txt', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520fe391",
   "metadata": {},
   "source": [
    "**mAP**<br>\n",
    "image_mpp default: .26<br>\n",
    "image_mpp=1: .39<br>\n",
    "image_mpp=2: .15<br>\n",
    "\n",
    "**AP for M872956_JML_Position8_CD3_test_img**<br>\n",
    "image_mpp default: 0.27 <br>\n",
    "image_mpp=1: .46<br>\n",
    "image_mpp=2: .16<br>\n",
    "For comparison, when model is trained with demo nuclear data, best performance is <br>\n",
    "image_mpp=2: .3<br>\n",
    "And with the pretrained DeepCell nuclear segmentation model, best performance is <br>\n",
    "image_mpp=1: 0.37<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32287508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more detailed mapping of image_mpp parameter\n",
    "AP_mat=[]\n",
    "for CURR_IM_NAME in FILENAMES:\n",
    "    print(CURR_IM_NAME)\n",
    "    im0 = io.imread(os.path.join(INPUT_PATH, CURR_IM_NAME))\n",
    "    mask_true=io.imread(os.path.join(INPUT_PATH, CURR_IM_NAME.replace(\"img\",\"masks\")))\n",
    "\n",
    "    x = np.expand_dims(im0, axis=-1)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    y, tile_info = app._tile_input(x)\n",
    "    AP_arr=[]\n",
    "    for mpp in np.linspace(start=0.7, stop=1.6, num=10):\n",
    "        prd = app._untile_output(app.predict(y, image_mpp=mpp), tile_info)[0,:,:,0]\n",
    "        a=syotil.csi(mask_true, prd)\n",
    "        AP_arr.append(a)\n",
    "    AP_mat.append(AP_arr)\n",
    "#AP_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774d401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.index(np.max(x)) for x in AP_mat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cee064",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(start=0.7, stop=1.6, num=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a258d9cc",
   "metadata": {},
   "source": [
    "image_mpp 1.1 seems best, but 1 is close enough"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
