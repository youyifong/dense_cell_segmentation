{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e4f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "from timeit import default_timer\n",
    "import ssl \n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import syotil\n",
    "from skimage import io\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import MSE\n",
    "from tensorflow.python.data import Dataset\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "from deepcell import losses\n",
    "from deepcell import image_generators\n",
    "from deepcell.utils import train_utils\n",
    "from deepcell.utils import tracking_utils\n",
    "from deepcell.utils.data_utils import get_data\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "from deepcell.utils.train_utils import get_callbacks\n",
    "from deepcell.utils.train_utils import count_gpus\n",
    "from deepcell.applications import CytoplasmSegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089068a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image files\n",
    "imgfiles = glob.glob('images/training/*_img.png')\n",
    "print(imgfiles)\n",
    "\n",
    "# show one file\n",
    "img=io.imread(imgfiles[0])\n",
    "print(img.shape)\n",
    "im=img[:,:,0]\n",
    "io.imshow(im)\n",
    "plt.show()\n",
    "\n",
    "imgs = [io.imread(imgfile)[:,:,0] for imgfile in imgfiles]\n",
    "\n",
    "X_train = tf.stack(imgs)\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "print(X_train.shape)\n",
    "\n",
    "# read mask files\n",
    "maskfiles = glob.glob('images/training/*_masks.png')\n",
    "img=io.imread(maskfiles[0])\n",
    "print(img.shape)\n",
    "im=img\n",
    "io.imshow(im)\n",
    "plt.show()\n",
    "\n",
    "masks = [io.imread(imgfile) for imgfile in maskfiles]\n",
    "\n",
    "y_train = tf.stack(masks)\n",
    "y_train = np.expand_dims(y_train, axis=-1)\n",
    "print(y_train.shape)\n",
    "\n",
    "np.savez(\"K_training_data\", X=X_train, y=y_train) # objects to save need to be key value pairs\n",
    "\n",
    "test_size=.2\n",
    "seed=0\n",
    "train_dict, test_dict = get_data(\"K_training_data.npz\", test_size=test_size, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cf7aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model\n",
    "# One-channel \n",
    "MODEL_PATH = ('https://deepcell-data.s3-us-west-1.amazonaws.com/saved-models/CytoplasmSegmentation-3.tar.gz')\n",
    "MODEL_HASH = '6a244f561b4d37169cb1a58b6029910f'\n",
    "archive_path = tf.keras.utils.get_file(\n",
    "                'CytoplasmSegmentation.tgz', MODEL_PATH,\n",
    "                file_hash=MODEL_HASH,\n",
    "                extract=True, cache_subdir='models')\n",
    "model_path = os.path.splitext(archive_path)[0]\n",
    "pretrained_model = tf.keras.models.load_model(model_path) # this copy will not be trained\n",
    "new_model = tf.keras.models.load_model(model_path)\n",
    "#new_model.save_weights('/home/shan/cyto_pretrained_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb77860",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '20221009'\n",
    "n_epoch = 100\n",
    "optimizer = Adam(learning_rate=1e-4, clipnorm=0.001)\n",
    "lr_sched = rate_scheduler(lr=1e-4, decay=0.99)\n",
    "batch_size = 1 # 8\n",
    "min_objects = 0  # throw out images with fewer than this many objects\n",
    "seed=0\n",
    "model_name\n",
    "\n",
    "datagen = image_generators.CroppingDataGenerator(\n",
    "    rotation_range=180,\n",
    "    shear_range=0,\n",
    "    zoom_range=(0.7, 1/0.7),\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    #crop_size=(256, 256)) # generate error\n",
    "    crop_size=(512, 512)) \n",
    "\n",
    "datagen_val = image_generators.SemanticDataGenerator(\n",
    "    rotation_range=0,\n",
    "    shear_range=0,\n",
    "    zoom_range=0,\n",
    "    horizontal_flip=0,\n",
    "    vertical_flip=0)\n",
    "    \n",
    "train_data = datagen.flow(\n",
    "    train_dict,\n",
    "    seed=seed,\n",
    "    transforms=['inner-distance','pixelwise'],\n",
    "    transforms_kwargs={'pixelwise':{'dilation_radius': 1}, \n",
    "                      'inner-distance': {'erosion_width': 1, 'alpha': 'auto'}},\n",
    "    min_objects=min_objects,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_data = datagen_val.flow(\n",
    "    test_dict,\n",
    "    seed=seed,\n",
    "    transforms=['inner-distance', 'pixelwise'],\n",
    "    transforms_kwargs={'pixelwise':{'dilation_radius': 1},\n",
    "                      'inner-distance': {'erosion_width': 1, 'alpha': 'auto'}},\n",
    "    min_objects=min_objects,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "# Define loss (create a dictionary of losses for each semantic head)\n",
    "\n",
    "def semantic_loss(n_classes):\n",
    "    def _semantic_loss(y_pred, y_true):\n",
    "        if n_classes > 1:\n",
    "            return 0.01 * losses.weighted_categorical_crossentropy(\n",
    "                y_pred, y_true, n_classes=n_classes)\n",
    "        return MSE(y_pred, y_true)\n",
    "    return _semantic_loss\n",
    "\n",
    "loss = {}\n",
    "\n",
    "# Give losses for all of the semantic heads\n",
    "for layer in new_model.layers:\n",
    "    if layer.name.startswith('semantic_'):\n",
    "        n_classes = layer.output_shape[-1]\n",
    "        loss[layer.name] = semantic_loss(n_classes)\n",
    "\n",
    "new_model.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005aed11",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = os.path.join('models')\n",
    "LOG_DIR = os.path.join('logs')\n",
    "if not os.path.exists(MODEL_DIR): os.mkdir(MODEL_DIR)\n",
    "if not os.path.exists(LOG_DIR): os.mkdir(LOG_DIR)    \n",
    "model_path = os.path.join(MODEL_DIR, '{}.h5'.format(model_name))\n",
    "loss_path = os.path.join(MODEL_DIR, '{}.npz'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4774a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_callbacks = get_callbacks(\n",
    "    model_path,\n",
    "    lr_sched=lr_sched,\n",
    "    tensorboard_log_dir=LOG_DIR,\n",
    "    save_weights_only=True,\n",
    "    #save_weights_only=num_gpus >= 2,\n",
    "    #monitor='val_loss',\n",
    "    monitor='loss', # training loss\n",
    "    verbose=1)\n",
    "\n",
    "start = default_timer()\n",
    "loss_history = new_model.fit_generator(\n",
    "    train_data,\n",
    "    steps_per_epoch=train_data.y.shape[0] // batch_size,\n",
    "    epochs=n_epoch,\n",
    "    #validation_data=val_data,\n",
    "    #validation_steps=val_data.y.shape[0] // batch_size,\n",
    "    callbacks=train_callbacks)\n",
    "training_time = default_timer() - start\n",
    "print('Training time: ', training_time, 'seconds.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f9e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test files\n",
    "im0 = io.imread('images/test/M872956_JML_Position8_CD3_test_img.png')\n",
    "print(im0.shape)\n",
    "im=im0\n",
    "io.imshow(im)\n",
    "plt.show()\n",
    "im = np.expand_dims(im, axis=-1)\n",
    "im = np.expand_dims(im, axis=0)\n",
    "\n",
    "mask_true=io.imread(\"images/test/M872956_JML_Position8_CD3_test_masks.png\")\n",
    "print(mask_true.shape)\n",
    "io.imshow(mask_true)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e77a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using newly trained model\n",
    "app = CytoplasmSegmentation(new_model)\n",
    "x=im\n",
    "y, tile_info = app._tile_input(x)\n",
    "#print(x.shape)\n",
    "#print(y.shape)\n",
    "#print(tile_info)\n",
    "pred = app.predict(y, image_mpp=1) \n",
    "prd = app._untile_output(pred, tile_info)\n",
    "io.imshow(prd[0,:,:,0])\n",
    "#plt.show()\n",
    "print(syotil.csi(mask_true, prd[0,:,:,0])) # 0.21 without passing image_mpp. Setting image_mpp to 1 improves to 0.37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae2af5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using CytoplasmSegmentation constructed with pretrained model\n",
    "# same as app = CytoplasmSegmentation() because the model is the default one\n",
    "app = CytoplasmSegmentation(pretrained_model) \n",
    "x=im\n",
    "y, tile_info = app._tile_input(x)\n",
    "#print(x.shape)\n",
    "#print(y.shape)\n",
    "#print(tile_info)\n",
    "pred = app.predict(y, image_mpp=1) \n",
    "prd = app._untile_output(pred, tile_info)\n",
    "io.imshow(prd[0,:,:,0])\n",
    "#plt.show()\n",
    "print(syotil.csi(mask_true, prd[0,:,:,0])) # 0.21 without passing image_mpp. Setting image_mpp to 1 improves to 0.37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae73c131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
