{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05468ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepcell\n",
    "import syotil\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.losses import MSE\n",
    "\n",
    "from deepcell.utils.train_utils import rate_scheduler, get_callbacks, count_gpus\n",
    "from deepcell.losses import weighted_categorical_crossentropy\n",
    "from deepcell.model_zoo.panopticnet import PanopticNet\n",
    "from deepcell_toolbox.deep_watershed import deep_watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "593d8ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = ('https://deepcell-data.s3-us-west-1.amazonaws.com/'\n",
    "            'demos/janelia/hela_s3_{}_256.npz')\n",
    "\n",
    "nuclear = deepcell.datasets.Dataset(\n",
    "    path='nuclear.npz',\n",
    "    url=base_url.format('nuclear'),\n",
    "    file_hash='04a200f437aa2f7c66d636c84c379ba7',\n",
    "    metadata=None\n",
    ")\n",
    "\n",
    "fluo_cyto = deepcell.datasets.Dataset(\n",
    "    path='fluo_cyto.npz',\n",
    "    url=base_url.format('fluo_cyto'),\n",
    "    file_hash='6a8a3ba4ddf3de8bb90776fa41a5a664',\n",
    "    metadata=None\n",
    ")\n",
    "\n",
    "phase = deepcell.datasets.Dataset(\n",
    "    path='phase.npz',\n",
    "    url=base_url.format('phase'),\n",
    "    file_hash='c56df51039fe6cae15c818118dfb8ce8',\n",
    "    metadata=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73d0c5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (1872, 256, 256, 1)\n",
      "X_test.shape: (468, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "from deepcell import image_generators\n",
    "\n",
    "dataset = fluo_cyto  # Change this to another dataset! (nuclear, phase, fluo_cyto)\n",
    "\n",
    "min_objects = 2\n",
    "\n",
    "test_size = 0.2 # fraction of data saved as test\n",
    "seed = 0 # seed for random train-test split\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = dataset.load_data(\n",
    "    test_size=test_size, seed=seed)\n",
    "\n",
    "print('X_train.shape: {}\\nX_test.shape: {}'.format(\n",
    "    X_train.shape, X_test.shape))\n",
    "transforms = ['inner-distance', 'outer-distance', 'fgbg']\n",
    "transforms_kwargs = {'outer-distance': {'erosion_width': 0}}\n",
    "\n",
    "\n",
    "# use augmentation for training but not validation\n",
    "datagen = image_generators.SemanticDataGenerator(\n",
    "    rotation_range=180,\n",
    "    fill_mode='reflect',\n",
    "    zoom_range=(0.75, 1.25),\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "\n",
    "datagen_val = image_generators.SemanticDataGenerator()\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "train_data = datagen.flow(\n",
    "    {'X': X_train, 'y': y_train},\n",
    "    seed=seed,\n",
    "    transforms=transforms,\n",
    "    transforms_kwargs=transforms_kwargs,\n",
    "    min_objects=min_objects,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_data = datagen_val.flow(\n",
    "    {'X': X_test, 'y': y_test},\n",
    "    seed=seed,\n",
    "    transforms=transforms,\n",
    "    transforms_kwargs=transforms_kwargs,\n",
    "    min_objects=min_objects,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ebc07f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 17:14:05.689177: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-10-10 17:14:07.038787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10429 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:5e:00.0, compute capability: 6.1\n",
      "/app/software/TensorFlow/2.7.1-foss-2021b-CUDA-11.4.1/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "semantic_classes = [1, 1, 2] # inner distance, outer distance, fgbg\n",
    "\n",
    "model = PanopticNet(\n",
    "    backbone='resnet50',\n",
    "    input_shape=X_train.shape[1:],\n",
    "    norm_method='whole_image',\n",
    "    num_semantic_classes=semantic_classes)\n",
    "\n",
    "n_epoch = 5\n",
    "\n",
    "lr = 1e-4\n",
    "optimizer = Adam(lr=lr, clipnorm=0.001)\n",
    "lr_sched = rate_scheduler(lr=lr, decay=0.99)\n",
    "\n",
    "# Create a dictionary of losses for each semantic head\n",
    "\n",
    "def semantic_loss(n_classes):\n",
    "    def _semantic_loss(y_pred, y_true):\n",
    "        if n_classes > 1:\n",
    "            return 0.01 * weighted_categorical_crossentropy(\n",
    "                y_pred, y_true, n_classes=n_classes)\n",
    "        return MSE(y_pred, y_true)\n",
    "    return _semantic_loss\n",
    "\n",
    "loss = {}\n",
    "\n",
    "# Give losses for all of the semantic heads\n",
    "for layer in model.layers:\n",
    "    if layer.name.startswith('semantic_'):\n",
    "        n_classes = layer.output_shape[-1]\n",
    "        loss[layer.name] = semantic_loss(n_classes)\n",
    "        \n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "[(layer.name, layer.output_shape) for layer in filter(lambda x: x.name.startswith('semantic_'), model.layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1fab4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 1 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 17:14:38.548972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 10429 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:5e:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 17:14:53.259875: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - ETA: 0s - loss: 0.0251 - semantic_0_loss: 0.0076 - semantic_1_loss: 0.0158 - semantic_2_loss: 0.0017\n",
      "Epoch 00001: val_loss improved from inf to 0.05939, saving model to phase_deep_watershed.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/software/TensorFlow/2.7.1-foss-2021b-CUDA-11.4.1/lib/python3.9/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - 85s 288ms/step - loss: 0.0251 - semantic_0_loss: 0.0076 - semantic_1_loss: 0.0158 - semantic_2_loss: 0.0017 - val_loss: 0.0594 - val_semantic_0_loss: 0.0038 - val_semantic_1_loss: 0.0465 - val_semantic_2_loss: 0.0091 - lr: 1.0000e-04\n",
      "Epoch 2/5\n",
      "234/234 [==============================] - ETA: 0s - loss: 0.0084 - semantic_0_loss: 0.0021 - semantic_1_loss: 0.0056 - semantic_2_loss: 7.7318e-04\n",
      "Epoch 00002: val_loss improved from 0.05939 to 0.02419, saving model to phase_deep_watershed.h5\n",
      "234/234 [==============================] - 69s 292ms/step - loss: 0.0084 - semantic_0_loss: 0.0021 - semantic_1_loss: 0.0056 - semantic_2_loss: 7.7318e-04 - val_loss: 0.0242 - val_semantic_0_loss: 0.0030 - val_semantic_1_loss: 0.0179 - val_semantic_2_loss: 0.0033 - lr: 9.9000e-05\n",
      "Epoch 3/5\n",
      "234/234 [==============================] - ETA: 0s - loss: 0.0074 - semantic_0_loss: 0.0019 - semantic_1_loss: 0.0048 - semantic_2_loss: 6.8404e-04\n",
      "Epoch 00003: val_loss improved from 0.02419 to 0.01255, saving model to phase_deep_watershed.h5\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.0074 - semantic_0_loss: 0.0019 - semantic_1_loss: 0.0048 - semantic_2_loss: 6.8404e-04 - val_loss: 0.0125 - val_semantic_0_loss: 0.0024 - val_semantic_1_loss: 0.0086 - val_semantic_2_loss: 0.0016 - lr: 9.8010e-05\n",
      "Epoch 4/5\n",
      "234/234 [==============================] - ETA: 0s - loss: 0.0066 - semantic_0_loss: 0.0018 - semantic_1_loss: 0.0042 - semantic_2_loss: 6.4138e-04\n",
      "Epoch 00004: val_loss improved from 0.01255 to 0.01006, saving model to phase_deep_watershed.h5\n",
      "234/234 [==============================] - 70s 298ms/step - loss: 0.0066 - semantic_0_loss: 0.0018 - semantic_1_loss: 0.0042 - semantic_2_loss: 6.4138e-04 - val_loss: 0.0101 - val_semantic_0_loss: 0.0022 - val_semantic_1_loss: 0.0064 - val_semantic_2_loss: 0.0015 - lr: 9.7030e-05\n",
      "Epoch 5/5\n",
      "234/234 [==============================] - ETA: 0s - loss: 0.0062 - semantic_0_loss: 0.0017 - semantic_1_loss: 0.0039 - semantic_2_loss: 6.1871e-04\n",
      "Epoch 00005: val_loss improved from 0.01006 to 0.00643, saving model to phase_deep_watershed.h5\n",
      "234/234 [==============================] - 68s 291ms/step - loss: 0.0062 - semantic_0_loss: 0.0017 - semantic_1_loss: 0.0039 - semantic_2_loss: 6.1871e-04 - val_loss: 0.0064 - val_semantic_0_loss: 0.0020 - val_semantic_1_loss: 0.0039 - val_semantic_2_loss: 5.9846e-04 - lr: 9.6060e-05\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "from deepcell.utils.train_utils import get_callbacks\n",
    "from deepcell.utils.train_utils import count_gpus\n",
    "\n",
    "model_name = 'phase_deep_watershed'\n",
    "model_path = '{}.h5'.format(model_name)\n",
    "\n",
    "print('Training on', count_gpus(), 'GPUs.')\n",
    "\n",
    "train_callbacks = get_callbacks(\n",
    "    model_path,\n",
    "    lr_sched=lr_sched,\n",
    "    monitor='val_loss',\n",
    "    verbose=1)\n",
    "\n",
    "loss_history = model.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=train_data.y.shape[0] // batch_size,\n",
    "    epochs=n_epoch,\n",
    "    validation_data=val_data,\n",
    "    validation_steps=val_data.y.shape[0] // batch_size,\n",
    "    callbacks=train_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbf36df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prediction model\n",
    "\n",
    "from deepcell.model_zoo.panopticnet import PanopticNet\n",
    "\n",
    "prediction_model = PanopticNet(\n",
    "    backbone='resnet50',\n",
    "    norm_method='whole_image',\n",
    "    num_semantic_classes=[1, 1], # inner distance, outer distance\n",
    "    input_shape=X_train.shape[1:]\n",
    ")\n",
    "\n",
    "prediction_model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41bdf527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watershed segmentation of shape (468, 256, 256, 1) in 3.423900566995144 seconds.\n"
     ]
    }
   ],
   "source": [
    "# make predictions on testing data\n",
    "from timeit import default_timer\n",
    "\n",
    "start = default_timer()\n",
    "test_images = prediction_model.predict(X_test)\n",
    "watershed_time = default_timer() - start\n",
    "\n",
    "print('Watershed segmentation of shape', test_images[0].shape,\n",
    "      'in', watershed_time, 'seconds.')\n",
    "\n",
    "from deepcell_toolbox.deep_watershed import deep_watershed\n",
    "\n",
    "masks = deep_watershed(\n",
    "    test_images,\n",
    "    min_distance=10,\n",
    "    detection_threshold=0.1,\n",
    "    distance_threshold=0.01,\n",
    "    exclude_border=False,\n",
    "    small_objects_threshold=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d70549c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syotil.csi(y_test[0,:,:,0], masks[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "964e6197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "(256, 256)\n"
     ]
    }
   ],
   "source": [
    "# read CD3 data\n",
    "\n",
    "from skimage import io\n",
    "img=io.imread(\"images/square_patches/M872956_JML_Position8_CD3_img_patch256x256.png\")\n",
    "print(img.shape)\n",
    "X_cd3=img[:,:,2]\n",
    "#io.imshow(im)\n",
    "#plt.show()\n",
    "X_cd3=np.expand_dims(X_cd3, -1) \n",
    "X_cd3=np.expand_dims(X_cd3, 0) \n",
    "\n",
    "y_cd3=io.imread(\"images/square_patches/M872956_JML_Position8_CD3_masks_patch256x256.png\")\n",
    "print(y_cd3.shape)\n",
    "#io.imshow(mask_true)\n",
    "#plt.show()\n",
    "y_cd3=np.expand_dims(y_cd3, -1) \n",
    "y_cd3=np.expand_dims(y_cd3, 0) \n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "train_cd3 = datagen.flow(\n",
    "    {'X': X_cd3, 'y': y_cd3},\n",
    "    seed=seed,\n",
    "    transforms=transforms,\n",
    "    transforms_kwargs=transforms_kwargs,\n",
    "    min_objects=min_objects,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_cd3 = datagen_val.flow(\n",
    "    {'X': X_cd3, 'y': y_cd3},\n",
    "    seed=seed,\n",
    "    transforms=transforms,\n",
    "    transforms_kwargs=transforms_kwargs,\n",
    "    min_objects=min_objects,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d868286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on CD3 data\n",
    "from timeit import default_timer\n",
    "\n",
    "start = default_timer()\n",
    "test_images = prediction_model.predict(X_cd3)\n",
    "watershed_time = default_timer() - start\n",
    "\n",
    "from deepcell_toolbox.deep_watershed import deep_watershed\n",
    "\n",
    "pred_cd3 = deep_watershed(\n",
    "    test_images,\n",
    "    min_distance=0,\n",
    "    detection_threshold=0.001,\n",
    "    distance_threshold=0.0,\n",
    "    exclude_border=False,\n",
    "    small_objects_threshold=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07cd889a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 1) (1, 256, 256, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_cd3.shape, pred_cd3.shape)\n",
    "io.imshow(y_cd3[0,:,:,0])\n",
    "plt.show()\n",
    "io.imshow(pred_cd3[0,:,:,0])\n",
    "plt.show()\n",
    "syotil.csi(y_cd3[0,:,:,0], pred_cd3[0,:,:,0])\n",
    "# the cyto_fluo training data cells are bigger than CD3 cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3df2a5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0817 - semantic_0_loss: 0.0296 - semantic_1_loss: 0.0470 - semantic_2_loss: 0.0051\n",
      "Epoch 00001: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.0817 - semantic_0_loss: 0.0296 - semantic_1_loss: 0.0470 - semantic_2_loss: 0.0051 - val_loss: 0.0999 - val_semantic_0_loss: 0.0418 - val_semantic_1_loss: 0.0529 - val_semantic_2_loss: 0.0052 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0953 - semantic_0_loss: 0.0352 - semantic_1_loss: 0.0543 - semantic_2_loss: 0.0057\n",
      "Epoch 00002: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.0953 - semantic_0_loss: 0.0352 - semantic_1_loss: 0.0543 - semantic_2_loss: 0.0057 - val_loss: 0.0970 - val_semantic_0_loss: 0.0409 - val_semantic_1_loss: 0.0511 - val_semantic_2_loss: 0.0049 - lr: 9.9000e-05\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0812 - semantic_0_loss: 0.0320 - semantic_1_loss: 0.0448 - semantic_2_loss: 0.0044\n",
      "Epoch 00003: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0812 - semantic_0_loss: 0.0320 - semantic_1_loss: 0.0448 - semantic_2_loss: 0.0044 - val_loss: 0.0939 - val_semantic_0_loss: 0.0397 - val_semantic_1_loss: 0.0494 - val_semantic_2_loss: 0.0048 - lr: 9.8010e-05\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0705 - semantic_0_loss: 0.0269 - semantic_1_loss: 0.0399 - semantic_2_loss: 0.0038\n",
      "Epoch 00004: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.0705 - semantic_0_loss: 0.0269 - semantic_1_loss: 0.0399 - semantic_2_loss: 0.0038 - val_loss: 0.0916 - val_semantic_0_loss: 0.0388 - val_semantic_1_loss: 0.0482 - val_semantic_2_loss: 0.0046 - lr: 9.7030e-05\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0676 - semantic_0_loss: 0.0282 - semantic_1_loss: 0.0362 - semantic_2_loss: 0.0031\n",
      "Epoch 00005: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0676 - semantic_0_loss: 0.0282 - semantic_1_loss: 0.0362 - semantic_2_loss: 0.0031 - val_loss: 0.0897 - val_semantic_0_loss: 0.0379 - val_semantic_1_loss: 0.0473 - val_semantic_2_loss: 0.0046 - lr: 9.6060e-05\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0625 - semantic_0_loss: 0.0246 - semantic_1_loss: 0.0346 - semantic_2_loss: 0.0033\n",
      "Epoch 00006: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0625 - semantic_0_loss: 0.0246 - semantic_1_loss: 0.0346 - semantic_2_loss: 0.0033 - val_loss: 0.0877 - val_semantic_0_loss: 0.0370 - val_semantic_1_loss: 0.0462 - val_semantic_2_loss: 0.0045 - lr: 9.5099e-05\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0761 - semantic_0_loss: 0.0289 - semantic_1_loss: 0.0431 - semantic_2_loss: 0.0040\n",
      "Epoch 00007: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0761 - semantic_0_loss: 0.0289 - semantic_1_loss: 0.0431 - semantic_2_loss: 0.0040 - val_loss: 0.0855 - val_semantic_0_loss: 0.0360 - val_semantic_1_loss: 0.0451 - val_semantic_2_loss: 0.0044 - lr: 9.4148e-05\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0966 - semantic_0_loss: 0.0355 - semantic_1_loss: 0.0565 - semantic_2_loss: 0.0046\n",
      "Epoch 00008: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0966 - semantic_0_loss: 0.0355 - semantic_1_loss: 0.0565 - semantic_2_loss: 0.0046 - val_loss: 0.0835 - val_semantic_0_loss: 0.0351 - val_semantic_1_loss: 0.0441 - val_semantic_2_loss: 0.0044 - lr: 9.3207e-05\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0541 - semantic_0_loss: 0.0218 - semantic_1_loss: 0.0293 - semantic_2_loss: 0.0030\n",
      "Epoch 00009: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0541 - semantic_0_loss: 0.0218 - semantic_1_loss: 0.0293 - semantic_2_loss: 0.0030 - val_loss: 0.0818 - val_semantic_0_loss: 0.0343 - val_semantic_1_loss: 0.0432 - val_semantic_2_loss: 0.0043 - lr: 9.2274e-05\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0753 - semantic_0_loss: 0.0303 - semantic_1_loss: 0.0410 - semantic_2_loss: 0.0040\n",
      "Epoch 00010: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0753 - semantic_0_loss: 0.0303 - semantic_1_loss: 0.0410 - semantic_2_loss: 0.0040 - val_loss: 0.0800 - val_semantic_0_loss: 0.0335 - val_semantic_1_loss: 0.0422 - val_semantic_2_loss: 0.0042 - lr: 9.1352e-05\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0658 - semantic_0_loss: 0.0259 - semantic_1_loss: 0.0365 - semantic_2_loss: 0.0034\n",
      "Epoch 00011: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.0658 - semantic_0_loss: 0.0259 - semantic_1_loss: 0.0365 - semantic_2_loss: 0.0034 - val_loss: 0.0787 - val_semantic_0_loss: 0.0329 - val_semantic_1_loss: 0.0416 - val_semantic_2_loss: 0.0042 - lr: 9.0438e-05\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0731 - semantic_0_loss: 0.0305 - semantic_1_loss: 0.0390 - semantic_2_loss: 0.0036\n",
      "Epoch 00012: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0731 - semantic_0_loss: 0.0305 - semantic_1_loss: 0.0390 - semantic_2_loss: 0.0036 - val_loss: 0.0769 - val_semantic_0_loss: 0.0322 - val_semantic_1_loss: 0.0406 - val_semantic_2_loss: 0.0041 - lr: 8.9534e-05\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0591 - semantic_0_loss: 0.0239 - semantic_1_loss: 0.0320 - semantic_2_loss: 0.0032\n",
      "Epoch 00013: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0591 - semantic_0_loss: 0.0239 - semantic_1_loss: 0.0320 - semantic_2_loss: 0.0032 - val_loss: 0.0745 - val_semantic_0_loss: 0.0313 - val_semantic_1_loss: 0.0392 - val_semantic_2_loss: 0.0039 - lr: 8.8638e-05\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0750 - semantic_0_loss: 0.0292 - semantic_1_loss: 0.0420 - semantic_2_loss: 0.0038\n",
      "Epoch 00014: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0750 - semantic_0_loss: 0.0292 - semantic_1_loss: 0.0420 - semantic_2_loss: 0.0038 - val_loss: 0.0724 - val_semantic_0_loss: 0.0305 - val_semantic_1_loss: 0.0381 - val_semantic_2_loss: 0.0038 - lr: 8.7752e-05\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0649 - semantic_0_loss: 0.0260 - semantic_1_loss: 0.0356 - semantic_2_loss: 0.0032\n",
      "Epoch 00015: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.0649 - semantic_0_loss: 0.0260 - semantic_1_loss: 0.0356 - semantic_2_loss: 0.0032 - val_loss: 0.0704 - val_semantic_0_loss: 0.0298 - val_semantic_1_loss: 0.0369 - val_semantic_2_loss: 0.0037 - lr: 8.6875e-05\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0599 - semantic_0_loss: 0.0248 - semantic_1_loss: 0.0318 - semantic_2_loss: 0.0033\n",
      "Epoch 00016: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0599 - semantic_0_loss: 0.0248 - semantic_1_loss: 0.0318 - semantic_2_loss: 0.0033 - val_loss: 0.0688 - val_semantic_0_loss: 0.0292 - val_semantic_1_loss: 0.0360 - val_semantic_2_loss: 0.0036 - lr: 8.6006e-05\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0741 - semantic_0_loss: 0.0293 - semantic_1_loss: 0.0409 - semantic_2_loss: 0.0039\n",
      "Epoch 00017: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.0741 - semantic_0_loss: 0.0293 - semantic_1_loss: 0.0409 - semantic_2_loss: 0.0039 - val_loss: 0.0674 - val_semantic_0_loss: 0.0288 - val_semantic_1_loss: 0.0351 - val_semantic_2_loss: 0.0035 - lr: 8.5146e-05\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0736 - semantic_0_loss: 0.0291 - semantic_1_loss: 0.0409 - semantic_2_loss: 0.0036\n",
      "Epoch 00018: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0736 - semantic_0_loss: 0.0291 - semantic_1_loss: 0.0409 - semantic_2_loss: 0.0036 - val_loss: 0.0666 - val_semantic_0_loss: 0.0286 - val_semantic_1_loss: 0.0345 - val_semantic_2_loss: 0.0035 - lr: 8.4294e-05\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0535 - semantic_0_loss: 0.0223 - semantic_1_loss: 0.0282 - semantic_2_loss: 0.0030\n",
      "Epoch 00019: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.0535 - semantic_0_loss: 0.0223 - semantic_1_loss: 0.0282 - semantic_2_loss: 0.0030 - val_loss: 0.0659 - val_semantic_0_loss: 0.0285 - val_semantic_1_loss: 0.0340 - val_semantic_2_loss: 0.0034 - lr: 8.3451e-05\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0615 - semantic_0_loss: 0.0238 - semantic_1_loss: 0.0345 - semantic_2_loss: 0.0033\n",
      "Epoch 00020: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0615 - semantic_0_loss: 0.0238 - semantic_1_loss: 0.0345 - semantic_2_loss: 0.0033 - val_loss: 0.0654 - val_semantic_0_loss: 0.0284 - val_semantic_1_loss: 0.0336 - val_semantic_2_loss: 0.0034 - lr: 8.2617e-05\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0632 - semantic_0_loss: 0.0255 - semantic_1_loss: 0.0344 - semantic_2_loss: 0.0033\n",
      "Epoch 00021: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.0632 - semantic_0_loss: 0.0255 - semantic_1_loss: 0.0344 - semantic_2_loss: 0.0033 - val_loss: 0.0644 - val_semantic_0_loss: 0.0281 - val_semantic_1_loss: 0.0330 - val_semantic_2_loss: 0.0033 - lr: 8.1791e-05\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0483 - semantic_0_loss: 0.0196 - semantic_1_loss: 0.0259 - semantic_2_loss: 0.0028\n",
      "Epoch 00022: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0483 - semantic_0_loss: 0.0196 - semantic_1_loss: 0.0259 - semantic_2_loss: 0.0028 - val_loss: 0.0635 - val_semantic_0_loss: 0.0278 - val_semantic_1_loss: 0.0325 - val_semantic_2_loss: 0.0033 - lr: 8.0973e-05\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0479 - semantic_0_loss: 0.0192 - semantic_1_loss: 0.0259 - semantic_2_loss: 0.0028\n",
      "Epoch 00023: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0479 - semantic_0_loss: 0.0192 - semantic_1_loss: 0.0259 - semantic_2_loss: 0.0028 - val_loss: 0.0626 - val_semantic_0_loss: 0.0275 - val_semantic_1_loss: 0.0318 - val_semantic_2_loss: 0.0033 - lr: 8.0163e-05\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0541 - semantic_0_loss: 0.0217 - semantic_1_loss: 0.0295 - semantic_2_loss: 0.0029\n",
      "Epoch 00024: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0541 - semantic_0_loss: 0.0217 - semantic_1_loss: 0.0295 - semantic_2_loss: 0.0029 - val_loss: 0.0614 - val_semantic_0_loss: 0.0271 - val_semantic_1_loss: 0.0311 - val_semantic_2_loss: 0.0032 - lr: 7.9361e-05\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0696 - semantic_0_loss: 0.0269 - semantic_1_loss: 0.0388 - semantic_2_loss: 0.0038\n",
      "Epoch 00025: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0696 - semantic_0_loss: 0.0269 - semantic_1_loss: 0.0388 - semantic_2_loss: 0.0038 - val_loss: 0.0605 - val_semantic_0_loss: 0.0269 - val_semantic_1_loss: 0.0304 - val_semantic_2_loss: 0.0032 - lr: 7.8568e-05\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0460 - semantic_0_loss: 0.0185 - semantic_1_loss: 0.0246 - semantic_2_loss: 0.0030\n",
      "Epoch 00026: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.0460 - semantic_0_loss: 0.0185 - semantic_1_loss: 0.0246 - semantic_2_loss: 0.0030 - val_loss: 0.0600 - val_semantic_0_loss: 0.0268 - val_semantic_1_loss: 0.0300 - val_semantic_2_loss: 0.0032 - lr: 7.7782e-05\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0545 - semantic_0_loss: 0.0198 - semantic_1_loss: 0.0317 - semantic_2_loss: 0.0030\n",
      "Epoch 00027: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0545 - semantic_0_loss: 0.0198 - semantic_1_loss: 0.0317 - semantic_2_loss: 0.0030 - val_loss: 0.0599 - val_semantic_0_loss: 0.0270 - val_semantic_1_loss: 0.0298 - val_semantic_2_loss: 0.0032 - lr: 7.7004e-05\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0518 - semantic_0_loss: 0.0209 - semantic_1_loss: 0.0279 - semantic_2_loss: 0.0030\n",
      "Epoch 00028: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0518 - semantic_0_loss: 0.0209 - semantic_1_loss: 0.0279 - semantic_2_loss: 0.0030 - val_loss: 0.0598 - val_semantic_0_loss: 0.0270 - val_semantic_1_loss: 0.0296 - val_semantic_2_loss: 0.0032 - lr: 7.6234e-05\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0417 - semantic_0_loss: 0.0168 - semantic_1_loss: 0.0222 - semantic_2_loss: 0.0027\n",
      "Epoch 00029: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0417 - semantic_0_loss: 0.0168 - semantic_1_loss: 0.0222 - semantic_2_loss: 0.0027 - val_loss: 0.0595 - val_semantic_0_loss: 0.0270 - val_semantic_1_loss: 0.0294 - val_semantic_2_loss: 0.0032 - lr: 7.5472e-05\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0616 - semantic_0_loss: 0.0242 - semantic_1_loss: 0.0341 - semantic_2_loss: 0.0033\n",
      "Epoch 00030: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0616 - semantic_0_loss: 0.0242 - semantic_1_loss: 0.0341 - semantic_2_loss: 0.0033 - val_loss: 0.0590 - val_semantic_0_loss: 0.0268 - val_semantic_1_loss: 0.0290 - val_semantic_2_loss: 0.0031 - lr: 7.4717e-05\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0472 - semantic_0_loss: 0.0196 - semantic_1_loss: 0.0249 - semantic_2_loss: 0.0027\n",
      "Epoch 00031: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0472 - semantic_0_loss: 0.0196 - semantic_1_loss: 0.0249 - semantic_2_loss: 0.0027 - val_loss: 0.0585 - val_semantic_0_loss: 0.0266 - val_semantic_1_loss: 0.0288 - val_semantic_2_loss: 0.0031 - lr: 7.3970e-05\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0613 - semantic_0_loss: 0.0234 - semantic_1_loss: 0.0343 - semantic_2_loss: 0.0035\n",
      "Epoch 00032: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.0613 - semantic_0_loss: 0.0234 - semantic_1_loss: 0.0343 - semantic_2_loss: 0.0035 - val_loss: 0.0578 - val_semantic_0_loss: 0.0263 - val_semantic_1_loss: 0.0284 - val_semantic_2_loss: 0.0031 - lr: 7.3230e-05\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0588 - semantic_0_loss: 0.0232 - semantic_1_loss: 0.0322 - semantic_2_loss: 0.0034\n",
      "Epoch 00033: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0588 - semantic_0_loss: 0.0232 - semantic_1_loss: 0.0322 - semantic_2_loss: 0.0034 - val_loss: 0.0571 - val_semantic_0_loss: 0.0260 - val_semantic_1_loss: 0.0280 - val_semantic_2_loss: 0.0031 - lr: 7.2498e-05\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0437 - semantic_0_loss: 0.0171 - semantic_1_loss: 0.0237 - semantic_2_loss: 0.0029\n",
      "Epoch 00034: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.0437 - semantic_0_loss: 0.0171 - semantic_1_loss: 0.0237 - semantic_2_loss: 0.0029 - val_loss: 0.0565 - val_semantic_0_loss: 0.0257 - val_semantic_1_loss: 0.0277 - val_semantic_2_loss: 0.0031 - lr: 7.1773e-05\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 0.0575 - semantic_0_loss: 0.0213 - semantic_1_loss: 0.0332 - semantic_2_loss: 0.0030\n",
      "Epoch 00035: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0575 - semantic_0_loss: 0.0213 - semantic_1_loss: 0.0332 - semantic_2_loss: 0.0030 - val_loss: 0.0560 - val_semantic_0_loss: 0.0255 - val_semantic_1_loss: 0.0274 - val_semantic_2_loss: 0.0031 - lr: 7.1055e-05\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0615 - semantic_0_loss: 0.0238 - semantic_1_loss: 0.0341 - semantic_2_loss: 0.0037\n",
      "Epoch 00036: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.0615 - semantic_0_loss: 0.0238 - semantic_1_loss: 0.0341 - semantic_2_loss: 0.0037 - val_loss: 0.0555 - val_semantic_0_loss: 0.0254 - val_semantic_1_loss: 0.0271 - val_semantic_2_loss: 0.0030 - lr: 7.0345e-05\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0428 - semantic_0_loss: 0.0172 - semantic_1_loss: 0.0228 - semantic_2_loss: 0.0028\n",
      "Epoch 00037: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0428 - semantic_0_loss: 0.0172 - semantic_1_loss: 0.0228 - semantic_2_loss: 0.0028 - val_loss: 0.0551 - val_semantic_0_loss: 0.0253 - val_semantic_1_loss: 0.0269 - val_semantic_2_loss: 0.0030 - lr: 6.9641e-05\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0444 - semantic_0_loss: 0.0178 - semantic_1_loss: 0.0234 - semantic_2_loss: 0.0032\n",
      "Epoch 00038: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.0444 - semantic_0_loss: 0.0178 - semantic_1_loss: 0.0234 - semantic_2_loss: 0.0032 - val_loss: 0.0547 - val_semantic_0_loss: 0.0251 - val_semantic_1_loss: 0.0267 - val_semantic_2_loss: 0.0030 - lr: 6.8945e-05\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0483 - semantic_0_loss: 0.0188 - semantic_1_loss: 0.0264 - semantic_2_loss: 0.0030\n",
      "Epoch 00039: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0483 - semantic_0_loss: 0.0188 - semantic_1_loss: 0.0264 - semantic_2_loss: 0.0030 - val_loss: 0.0541 - val_semantic_0_loss: 0.0249 - val_semantic_1_loss: 0.0264 - val_semantic_2_loss: 0.0029 - lr: 6.8255e-05\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0493 - semantic_0_loss: 0.0193 - semantic_1_loss: 0.0272 - semantic_2_loss: 0.0027\n",
      "Epoch 00040: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0493 - semantic_0_loss: 0.0193 - semantic_1_loss: 0.0272 - semantic_2_loss: 0.0027 - val_loss: 0.0536 - val_semantic_0_loss: 0.0247 - val_semantic_1_loss: 0.0261 - val_semantic_2_loss: 0.0029 - lr: 6.7573e-05\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0603 - semantic_0_loss: 0.0234 - semantic_1_loss: 0.0337 - semantic_2_loss: 0.0033\n",
      "Epoch 00041: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.0603 - semantic_0_loss: 0.0234 - semantic_1_loss: 0.0337 - semantic_2_loss: 0.0033 - val_loss: 0.0532 - val_semantic_0_loss: 0.0245 - val_semantic_1_loss: 0.0258 - val_semantic_2_loss: 0.0029 - lr: 6.6897e-05\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0542 - semantic_0_loss: 0.0217 - semantic_1_loss: 0.0294 - semantic_2_loss: 0.0032\n",
      "Epoch 00042: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0542 - semantic_0_loss: 0.0217 - semantic_1_loss: 0.0294 - semantic_2_loss: 0.0032 - val_loss: 0.0527 - val_semantic_0_loss: 0.0243 - val_semantic_1_loss: 0.0256 - val_semantic_2_loss: 0.0029 - lr: 6.6228e-05\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0520 - semantic_0_loss: 0.0209 - semantic_1_loss: 0.0280 - semantic_2_loss: 0.0031\n",
      "Epoch 00043: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0520 - semantic_0_loss: 0.0209 - semantic_1_loss: 0.0280 - semantic_2_loss: 0.0031 - val_loss: 0.0523 - val_semantic_0_loss: 0.0241 - val_semantic_1_loss: 0.0253 - val_semantic_2_loss: 0.0028 - lr: 6.5566e-05\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0363 - semantic_0_loss: 0.0142 - semantic_1_loss: 0.0195 - semantic_2_loss: 0.0026\n",
      "Epoch 00044: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0363 - semantic_0_loss: 0.0142 - semantic_1_loss: 0.0195 - semantic_2_loss: 0.0026 - val_loss: 0.0519 - val_semantic_0_loss: 0.0239 - val_semantic_1_loss: 0.0251 - val_semantic_2_loss: 0.0028 - lr: 6.4910e-05\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0434 - semantic_0_loss: 0.0160 - semantic_1_loss: 0.0248 - semantic_2_loss: 0.0027\n",
      "Epoch 00045: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0434 - semantic_0_loss: 0.0160 - semantic_1_loss: 0.0248 - semantic_2_loss: 0.0027 - val_loss: 0.0516 - val_semantic_0_loss: 0.0238 - val_semantic_1_loss: 0.0250 - val_semantic_2_loss: 0.0028 - lr: 6.4261e-05\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0338 - semantic_0_loss: 0.0132 - semantic_1_loss: 0.0180 - semantic_2_loss: 0.0026\n",
      "Epoch 00046: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0338 - semantic_0_loss: 0.0132 - semantic_1_loss: 0.0180 - semantic_2_loss: 0.0026 - val_loss: 0.0514 - val_semantic_0_loss: 0.0237 - val_semantic_1_loss: 0.0249 - val_semantic_2_loss: 0.0028 - lr: 6.3619e-05\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0489 - semantic_0_loss: 0.0194 - semantic_1_loss: 0.0269 - semantic_2_loss: 0.0027\n",
      "Epoch 00047: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0489 - semantic_0_loss: 0.0194 - semantic_1_loss: 0.0269 - semantic_2_loss: 0.0027 - val_loss: 0.0513 - val_semantic_0_loss: 0.0236 - val_semantic_1_loss: 0.0249 - val_semantic_2_loss: 0.0028 - lr: 6.2982e-05\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0402 - semantic_0_loss: 0.0156 - semantic_1_loss: 0.0220 - semantic_2_loss: 0.0026\n",
      "Epoch 00048: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.0402 - semantic_0_loss: 0.0156 - semantic_1_loss: 0.0220 - semantic_2_loss: 0.0026 - val_loss: 0.0513 - val_semantic_0_loss: 0.0236 - val_semantic_1_loss: 0.0249 - val_semantic_2_loss: 0.0028 - lr: 6.2353e-05\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0539 - semantic_0_loss: 0.0206 - semantic_1_loss: 0.0300 - semantic_2_loss: 0.0033\n",
      "Epoch 00049: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0539 - semantic_0_loss: 0.0206 - semantic_1_loss: 0.0300 - semantic_2_loss: 0.0033 - val_loss: 0.0513 - val_semantic_0_loss: 0.0237 - val_semantic_1_loss: 0.0249 - val_semantic_2_loss: 0.0028 - lr: 6.1729e-05\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0474 - semantic_0_loss: 0.0183 - semantic_1_loss: 0.0265 - semantic_2_loss: 0.0027\n",
      "Epoch 00050: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0474 - semantic_0_loss: 0.0183 - semantic_1_loss: 0.0265 - semantic_2_loss: 0.0027 - val_loss: 0.0513 - val_semantic_0_loss: 0.0237 - val_semantic_1_loss: 0.0248 - val_semantic_2_loss: 0.0028 - lr: 6.1112e-05\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0422 - semantic_0_loss: 0.0157 - semantic_1_loss: 0.0239 - semantic_2_loss: 0.0027\n",
      "Epoch 00051: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0422 - semantic_0_loss: 0.0157 - semantic_1_loss: 0.0239 - semantic_2_loss: 0.0027 - val_loss: 0.0512 - val_semantic_0_loss: 0.0236 - val_semantic_1_loss: 0.0248 - val_semantic_2_loss: 0.0028 - lr: 6.0501e-05\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0404 - semantic_0_loss: 0.0162 - semantic_1_loss: 0.0213 - semantic_2_loss: 0.0028\n",
      "Epoch 00052: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0404 - semantic_0_loss: 0.0162 - semantic_1_loss: 0.0213 - semantic_2_loss: 0.0028 - val_loss: 0.0511 - val_semantic_0_loss: 0.0235 - val_semantic_1_loss: 0.0248 - val_semantic_2_loss: 0.0028 - lr: 5.9896e-05\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0468 - semantic_0_loss: 0.0183 - semantic_1_loss: 0.0257 - semantic_2_loss: 0.0029\n",
      "Epoch 00053: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.0468 - semantic_0_loss: 0.0183 - semantic_1_loss: 0.0257 - semantic_2_loss: 0.0029 - val_loss: 0.0508 - val_semantic_0_loss: 0.0234 - val_semantic_1_loss: 0.0247 - val_semantic_2_loss: 0.0028 - lr: 5.9297e-05\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0367 - semantic_0_loss: 0.0149 - semantic_1_loss: 0.0190 - semantic_2_loss: 0.0027\n",
      "Epoch 00054: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0367 - semantic_0_loss: 0.0149 - semantic_1_loss: 0.0190 - semantic_2_loss: 0.0027 - val_loss: 0.0506 - val_semantic_0_loss: 0.0233 - val_semantic_1_loss: 0.0245 - val_semantic_2_loss: 0.0028 - lr: 5.8704e-05\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0479 - semantic_0_loss: 0.0192 - semantic_1_loss: 0.0258 - semantic_2_loss: 0.0029\n",
      "Epoch 00055: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.0479 - semantic_0_loss: 0.0192 - semantic_1_loss: 0.0258 - semantic_2_loss: 0.0029 - val_loss: 0.0503 - val_semantic_0_loss: 0.0232 - val_semantic_1_loss: 0.0243 - val_semantic_2_loss: 0.0027 - lr: 5.8117e-05\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0518 - semantic_0_loss: 0.0202 - semantic_1_loss: 0.0287 - semantic_2_loss: 0.0029\n",
      "Epoch 00056: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0518 - semantic_0_loss: 0.0202 - semantic_1_loss: 0.0287 - semantic_2_loss: 0.0029 - val_loss: 0.0500 - val_semantic_0_loss: 0.0232 - val_semantic_1_loss: 0.0241 - val_semantic_2_loss: 0.0027 - lr: 5.7535e-05\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0352 - semantic_0_loss: 0.0142 - semantic_1_loss: 0.0186 - semantic_2_loss: 0.0024\n",
      "Epoch 00057: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0352 - semantic_0_loss: 0.0142 - semantic_1_loss: 0.0186 - semantic_2_loss: 0.0024 - val_loss: 0.0499 - val_semantic_0_loss: 0.0233 - val_semantic_1_loss: 0.0239 - val_semantic_2_loss: 0.0027 - lr: 5.6960e-05\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0410 - semantic_0_loss: 0.0169 - semantic_1_loss: 0.0215 - semantic_2_loss: 0.0027\n",
      "Epoch 00058: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.0410 - semantic_0_loss: 0.0169 - semantic_1_loss: 0.0215 - semantic_2_loss: 0.0027 - val_loss: 0.0498 - val_semantic_0_loss: 0.0233 - val_semantic_1_loss: 0.0238 - val_semantic_2_loss: 0.0027 - lr: 5.6391e-05\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0359 - semantic_0_loss: 0.0141 - semantic_1_loss: 0.0194 - semantic_2_loss: 0.0024\n",
      "Epoch 00059: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0359 - semantic_0_loss: 0.0141 - semantic_1_loss: 0.0194 - semantic_2_loss: 0.0024 - val_loss: 0.0497 - val_semantic_0_loss: 0.0233 - val_semantic_1_loss: 0.0237 - val_semantic_2_loss: 0.0027 - lr: 5.5827e-05\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0360 - semantic_0_loss: 0.0146 - semantic_1_loss: 0.0189 - semantic_2_loss: 0.0025\n",
      "Epoch 00060: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.0360 - semantic_0_loss: 0.0146 - semantic_1_loss: 0.0189 - semantic_2_loss: 0.0025 - val_loss: 0.0496 - val_semantic_0_loss: 0.0233 - val_semantic_1_loss: 0.0236 - val_semantic_2_loss: 0.0027 - lr: 5.5268e-05\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0541 - semantic_0_loss: 0.0217 - semantic_1_loss: 0.0293 - semantic_2_loss: 0.0031\n",
      "Epoch 00061: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0541 - semantic_0_loss: 0.0217 - semantic_1_loss: 0.0293 - semantic_2_loss: 0.0031 - val_loss: 0.0495 - val_semantic_0_loss: 0.0233 - val_semantic_1_loss: 0.0236 - val_semantic_2_loss: 0.0027 - lr: 5.4716e-05\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0435 - semantic_0_loss: 0.0165 - semantic_1_loss: 0.0243 - semantic_2_loss: 0.0027\n",
      "Epoch 00062: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0435 - semantic_0_loss: 0.0165 - semantic_1_loss: 0.0243 - semantic_2_loss: 0.0027 - val_loss: 0.0496 - val_semantic_0_loss: 0.0233 - val_semantic_1_loss: 0.0236 - val_semantic_2_loss: 0.0026 - lr: 5.4169e-05\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0449 - semantic_0_loss: 0.0180 - semantic_1_loss: 0.0242 - semantic_2_loss: 0.0028\n",
      "Epoch 00063: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0449 - semantic_0_loss: 0.0180 - semantic_1_loss: 0.0242 - semantic_2_loss: 0.0028 - val_loss: 0.0497 - val_semantic_0_loss: 0.0234 - val_semantic_1_loss: 0.0237 - val_semantic_2_loss: 0.0026 - lr: 5.3627e-05\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0516 - semantic_0_loss: 0.0204 - semantic_1_loss: 0.0281 - semantic_2_loss: 0.0031\n",
      "Epoch 00064: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0516 - semantic_0_loss: 0.0204 - semantic_1_loss: 0.0281 - semantic_2_loss: 0.0031 - val_loss: 0.0499 - val_semantic_0_loss: 0.0235 - val_semantic_1_loss: 0.0238 - val_semantic_2_loss: 0.0026 - lr: 5.3091e-05\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0494 - semantic_0_loss: 0.0193 - semantic_1_loss: 0.0273 - semantic_2_loss: 0.0029\n",
      "Epoch 00065: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.0494 - semantic_0_loss: 0.0193 - semantic_1_loss: 0.0273 - semantic_2_loss: 0.0029 - val_loss: 0.0501 - val_semantic_0_loss: 0.0236 - val_semantic_1_loss: 0.0239 - val_semantic_2_loss: 0.0026 - lr: 5.2560e-05\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0427 - semantic_0_loss: 0.0169 - semantic_1_loss: 0.0230 - semantic_2_loss: 0.0027\n",
      "Epoch 00066: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.0427 - semantic_0_loss: 0.0169 - semantic_1_loss: 0.0230 - semantic_2_loss: 0.0027 - val_loss: 0.0502 - val_semantic_0_loss: 0.0236 - val_semantic_1_loss: 0.0240 - val_semantic_2_loss: 0.0026 - lr: 5.2034e-05\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0413 - semantic_0_loss: 0.0161 - semantic_1_loss: 0.0226 - semantic_2_loss: 0.0027\n",
      "Epoch 00067: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0413 - semantic_0_loss: 0.0161 - semantic_1_loss: 0.0226 - semantic_2_loss: 0.0027 - val_loss: 0.0501 - val_semantic_0_loss: 0.0234 - val_semantic_1_loss: 0.0240 - val_semantic_2_loss: 0.0026 - lr: 5.1514e-05\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0543 - semantic_0_loss: 0.0214 - semantic_1_loss: 0.0299 - semantic_2_loss: 0.0030\n",
      "Epoch 00068: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0543 - semantic_0_loss: 0.0214 - semantic_1_loss: 0.0299 - semantic_2_loss: 0.0030 - val_loss: 0.0501 - val_semantic_0_loss: 0.0234 - val_semantic_1_loss: 0.0241 - val_semantic_2_loss: 0.0026 - lr: 5.0999e-05\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 0.0491 - semantic_0_loss: 0.0185 - semantic_1_loss: 0.0278 - semantic_2_loss: 0.0028\n",
      "Epoch 00069: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0491 - semantic_0_loss: 0.0185 - semantic_1_loss: 0.0278 - semantic_2_loss: 0.0028 - val_loss: 0.0500 - val_semantic_0_loss: 0.0233 - val_semantic_1_loss: 0.0241 - val_semantic_2_loss: 0.0026 - lr: 5.0489e-05\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0480 - semantic_0_loss: 0.0187 - semantic_1_loss: 0.0265 - semantic_2_loss: 0.0028\n",
      "Epoch 00070: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0480 - semantic_0_loss: 0.0187 - semantic_1_loss: 0.0265 - semantic_2_loss: 0.0028 - val_loss: 0.0500 - val_semantic_0_loss: 0.0233 - val_semantic_1_loss: 0.0241 - val_semantic_2_loss: 0.0026 - lr: 4.9984e-05\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0481 - semantic_0_loss: 0.0194 - semantic_1_loss: 0.0261 - semantic_2_loss: 0.0027\n",
      "Epoch 00071: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0481 - semantic_0_loss: 0.0194 - semantic_1_loss: 0.0261 - semantic_2_loss: 0.0027 - val_loss: 0.0500 - val_semantic_0_loss: 0.0233 - val_semantic_1_loss: 0.0241 - val_semantic_2_loss: 0.0026 - lr: 4.9484e-05\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0491 - semantic_0_loss: 0.0202 - semantic_1_loss: 0.0259 - semantic_2_loss: 0.0029\n",
      "Epoch 00072: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.0491 - semantic_0_loss: 0.0202 - semantic_1_loss: 0.0259 - semantic_2_loss: 0.0029 - val_loss: 0.0501 - val_semantic_0_loss: 0.0234 - val_semantic_1_loss: 0.0241 - val_semantic_2_loss: 0.0026 - lr: 4.8989e-05\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0412 - semantic_0_loss: 0.0172 - semantic_1_loss: 0.0214 - semantic_2_loss: 0.0026\n",
      "Epoch 00073: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.0412 - semantic_0_loss: 0.0172 - semantic_1_loss: 0.0214 - semantic_2_loss: 0.0026 - val_loss: 0.0503 - val_semantic_0_loss: 0.0235 - val_semantic_1_loss: 0.0242 - val_semantic_2_loss: 0.0026 - lr: 4.8499e-05\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0462 - semantic_0_loss: 0.0176 - semantic_1_loss: 0.0257 - semantic_2_loss: 0.0029\n",
      "Epoch 00074: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0462 - semantic_0_loss: 0.0176 - semantic_1_loss: 0.0257 - semantic_2_loss: 0.0029 - val_loss: 0.0505 - val_semantic_0_loss: 0.0237 - val_semantic_1_loss: 0.0242 - val_semantic_2_loss: 0.0026 - lr: 4.8014e-05\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0470 - semantic_0_loss: 0.0182 - semantic_1_loss: 0.0259 - semantic_2_loss: 0.0028\n",
      "Epoch 00075: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0470 - semantic_0_loss: 0.0182 - semantic_1_loss: 0.0259 - semantic_2_loss: 0.0028 - val_loss: 0.0507 - val_semantic_0_loss: 0.0238 - val_semantic_1_loss: 0.0243 - val_semantic_2_loss: 0.0026 - lr: 4.7534e-05\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0466 - semantic_0_loss: 0.0190 - semantic_1_loss: 0.0248 - semantic_2_loss: 0.0028\n",
      "Epoch 00076: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.0466 - semantic_0_loss: 0.0190 - semantic_1_loss: 0.0248 - semantic_2_loss: 0.0028 - val_loss: 0.0508 - val_semantic_0_loss: 0.0240 - val_semantic_1_loss: 0.0243 - val_semantic_2_loss: 0.0026 - lr: 4.7059e-05\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0473 - semantic_0_loss: 0.0204 - semantic_1_loss: 0.0241 - semantic_2_loss: 0.0027\n",
      "Epoch 00077: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0473 - semantic_0_loss: 0.0204 - semantic_1_loss: 0.0241 - semantic_2_loss: 0.0027 - val_loss: 0.0510 - val_semantic_0_loss: 0.0240 - val_semantic_1_loss: 0.0243 - val_semantic_2_loss: 0.0026 - lr: 4.6588e-05\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0379 - semantic_0_loss: 0.0147 - semantic_1_loss: 0.0205 - semantic_2_loss: 0.0027\n",
      "Epoch 00078: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0379 - semantic_0_loss: 0.0147 - semantic_1_loss: 0.0205 - semantic_2_loss: 0.0027 - val_loss: 0.0512 - val_semantic_0_loss: 0.0241 - val_semantic_1_loss: 0.0245 - val_semantic_2_loss: 0.0026 - lr: 4.6122e-05\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0359 - semantic_0_loss: 0.0146 - semantic_1_loss: 0.0189 - semantic_2_loss: 0.0025\n",
      "Epoch 00079: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0359 - semantic_0_loss: 0.0146 - semantic_1_loss: 0.0189 - semantic_2_loss: 0.0025 - val_loss: 0.0513 - val_semantic_0_loss: 0.0242 - val_semantic_1_loss: 0.0246 - val_semantic_2_loss: 0.0026 - lr: 4.5661e-05\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0355 - semantic_0_loss: 0.0140 - semantic_1_loss: 0.0191 - semantic_2_loss: 0.0024\n",
      "Epoch 00080: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.0355 - semantic_0_loss: 0.0140 - semantic_1_loss: 0.0191 - semantic_2_loss: 0.0024 - val_loss: 0.0514 - val_semantic_0_loss: 0.0241 - val_semantic_1_loss: 0.0247 - val_semantic_2_loss: 0.0026 - lr: 4.5204e-05\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0559 - semantic_0_loss: 0.0218 - semantic_1_loss: 0.0308 - semantic_2_loss: 0.0032\n",
      "Epoch 00081: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0559 - semantic_0_loss: 0.0218 - semantic_1_loss: 0.0308 - semantic_2_loss: 0.0032 - val_loss: 0.0515 - val_semantic_0_loss: 0.0241 - val_semantic_1_loss: 0.0248 - val_semantic_2_loss: 0.0026 - lr: 4.4752e-05\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0410 - semantic_0_loss: 0.0161 - semantic_1_loss: 0.0223 - semantic_2_loss: 0.0026\n",
      "Epoch 00082: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.0410 - semantic_0_loss: 0.0161 - semantic_1_loss: 0.0223 - semantic_2_loss: 0.0026 - val_loss: 0.0514 - val_semantic_0_loss: 0.0241 - val_semantic_1_loss: 0.0248 - val_semantic_2_loss: 0.0026 - lr: 4.4305e-05\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0320 - semantic_0_loss: 0.0123 - semantic_1_loss: 0.0172 - semantic_2_loss: 0.0025\n",
      "Epoch 00083: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.0320 - semantic_0_loss: 0.0123 - semantic_1_loss: 0.0172 - semantic_2_loss: 0.0025 - val_loss: 0.0512 - val_semantic_0_loss: 0.0239 - val_semantic_1_loss: 0.0247 - val_semantic_2_loss: 0.0026 - lr: 4.3862e-05\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0472 - semantic_0_loss: 0.0190 - semantic_1_loss: 0.0255 - semantic_2_loss: 0.0027\n",
      "Epoch 00084: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0472 - semantic_0_loss: 0.0190 - semantic_1_loss: 0.0255 - semantic_2_loss: 0.0027 - val_loss: 0.0510 - val_semantic_0_loss: 0.0238 - val_semantic_1_loss: 0.0246 - val_semantic_2_loss: 0.0026 - lr: 4.3423e-05\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0372 - semantic_0_loss: 0.0150 - semantic_1_loss: 0.0197 - semantic_2_loss: 0.0024\n",
      "Epoch 00085: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0372 - semantic_0_loss: 0.0150 - semantic_1_loss: 0.0197 - semantic_2_loss: 0.0024 - val_loss: 0.0508 - val_semantic_0_loss: 0.0237 - val_semantic_1_loss: 0.0245 - val_semantic_2_loss: 0.0026 - lr: 4.2989e-05\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0488 - semantic_0_loss: 0.0214 - semantic_1_loss: 0.0248 - semantic_2_loss: 0.0027\n",
      "Epoch 00086: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0488 - semantic_0_loss: 0.0214 - semantic_1_loss: 0.0248 - semantic_2_loss: 0.0027 - val_loss: 0.0505 - val_semantic_0_loss: 0.0236 - val_semantic_1_loss: 0.0244 - val_semantic_2_loss: 0.0025 - lr: 4.2559e-05\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0380 - semantic_0_loss: 0.0164 - semantic_1_loss: 0.0192 - semantic_2_loss: 0.0024\n",
      "Epoch 00087: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0380 - semantic_0_loss: 0.0164 - semantic_1_loss: 0.0192 - semantic_2_loss: 0.0024 - val_loss: 0.0503 - val_semantic_0_loss: 0.0234 - val_semantic_1_loss: 0.0243 - val_semantic_2_loss: 0.0025 - lr: 4.2133e-05\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0540 - semantic_0_loss: 0.0208 - semantic_1_loss: 0.0303 - semantic_2_loss: 0.0030\n",
      "Epoch 00088: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.0540 - semantic_0_loss: 0.0208 - semantic_1_loss: 0.0303 - semantic_2_loss: 0.0030 - val_loss: 0.0501 - val_semantic_0_loss: 0.0233 - val_semantic_1_loss: 0.0242 - val_semantic_2_loss: 0.0025 - lr: 4.1712e-05\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0421 - semantic_0_loss: 0.0168 - semantic_1_loss: 0.0226 - semantic_2_loss: 0.0027\n",
      "Epoch 00089: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0421 - semantic_0_loss: 0.0168 - semantic_1_loss: 0.0226 - semantic_2_loss: 0.0027 - val_loss: 0.0499 - val_semantic_0_loss: 0.0232 - val_semantic_1_loss: 0.0241 - val_semantic_2_loss: 0.0025 - lr: 4.1295e-05\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0553 - semantic_0_loss: 0.0216 - semantic_1_loss: 0.0307 - semantic_2_loss: 0.0030\n",
      "Epoch 00090: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0553 - semantic_0_loss: 0.0216 - semantic_1_loss: 0.0307 - semantic_2_loss: 0.0030 - val_loss: 0.0497 - val_semantic_0_loss: 0.0232 - val_semantic_1_loss: 0.0240 - val_semantic_2_loss: 0.0025 - lr: 4.0882e-05\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0470 - semantic_0_loss: 0.0187 - semantic_1_loss: 0.0255 - semantic_2_loss: 0.0028\n",
      "Epoch 00091: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.0470 - semantic_0_loss: 0.0187 - semantic_1_loss: 0.0255 - semantic_2_loss: 0.0028 - val_loss: 0.0496 - val_semantic_0_loss: 0.0231 - val_semantic_1_loss: 0.0239 - val_semantic_2_loss: 0.0025 - lr: 4.0473e-05\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0368 - semantic_0_loss: 0.0147 - semantic_1_loss: 0.0196 - semantic_2_loss: 0.0025\n",
      "Epoch 00092: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0368 - semantic_0_loss: 0.0147 - semantic_1_loss: 0.0196 - semantic_2_loss: 0.0025 - val_loss: 0.0494 - val_semantic_0_loss: 0.0230 - val_semantic_1_loss: 0.0238 - val_semantic_2_loss: 0.0025 - lr: 4.0068e-05\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0455 - semantic_0_loss: 0.0186 - semantic_1_loss: 0.0242 - semantic_2_loss: 0.0028\n",
      "Epoch 00093: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0455 - semantic_0_loss: 0.0186 - semantic_1_loss: 0.0242 - semantic_2_loss: 0.0028 - val_loss: 0.0492 - val_semantic_0_loss: 0.0230 - val_semantic_1_loss: 0.0237 - val_semantic_2_loss: 0.0025 - lr: 3.9668e-05\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0370 - semantic_0_loss: 0.0145 - semantic_1_loss: 0.0199 - semantic_2_loss: 0.0026\n",
      "Epoch 00094: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.0370 - semantic_0_loss: 0.0145 - semantic_1_loss: 0.0199 - semantic_2_loss: 0.0026 - val_loss: 0.0490 - val_semantic_0_loss: 0.0229 - val_semantic_1_loss: 0.0236 - val_semantic_2_loss: 0.0025 - lr: 3.9271e-05\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0360 - semantic_0_loss: 0.0142 - semantic_1_loss: 0.0194 - semantic_2_loss: 0.0024\n",
      "Epoch 00095: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0360 - semantic_0_loss: 0.0142 - semantic_1_loss: 0.0194 - semantic_2_loss: 0.0024 - val_loss: 0.0488 - val_semantic_0_loss: 0.0227 - val_semantic_1_loss: 0.0235 - val_semantic_2_loss: 0.0025 - lr: 3.8878e-05\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0373 - semantic_0_loss: 0.0151 - semantic_1_loss: 0.0198 - semantic_2_loss: 0.0024\n",
      "Epoch 00096: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.0373 - semantic_0_loss: 0.0151 - semantic_1_loss: 0.0198 - semantic_2_loss: 0.0024 - val_loss: 0.0486 - val_semantic_0_loss: 0.0226 - val_semantic_1_loss: 0.0234 - val_semantic_2_loss: 0.0025 - lr: 3.8490e-05\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0392 - semantic_0_loss: 0.0142 - semantic_1_loss: 0.0225 - semantic_2_loss: 0.0024\n",
      "Epoch 00097: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0392 - semantic_0_loss: 0.0142 - semantic_1_loss: 0.0225 - semantic_2_loss: 0.0024 - val_loss: 0.0485 - val_semantic_0_loss: 0.0226 - val_semantic_1_loss: 0.0234 - val_semantic_2_loss: 0.0025 - lr: 3.8105e-05\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0435 - semantic_0_loss: 0.0170 - semantic_1_loss: 0.0238 - semantic_2_loss: 0.0026\n",
      "Epoch 00098: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0435 - semantic_0_loss: 0.0170 - semantic_1_loss: 0.0238 - semantic_2_loss: 0.0026 - val_loss: 0.0485 - val_semantic_0_loss: 0.0226 - val_semantic_1_loss: 0.0234 - val_semantic_2_loss: 0.0025 - lr: 3.7724e-05\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0429 - semantic_0_loss: 0.0170 - semantic_1_loss: 0.0232 - semantic_2_loss: 0.0027\n",
      "Epoch 00099: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0429 - semantic_0_loss: 0.0170 - semantic_1_loss: 0.0232 - semantic_2_loss: 0.0027 - val_loss: 0.0485 - val_semantic_0_loss: 0.0226 - val_semantic_1_loss: 0.0234 - val_semantic_2_loss: 0.0025 - lr: 3.7346e-05\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0470 - semantic_0_loss: 0.0189 - semantic_1_loss: 0.0251 - semantic_2_loss: 0.0029\n",
      "Epoch 00100: val_loss did not improve from 0.00643\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0470 - semantic_0_loss: 0.0189 - semantic_1_loss: 0.0251 - semantic_2_loss: 0.0029 - val_loss: 0.0485 - val_semantic_0_loss: 0.0226 - val_semantic_1_loss: 0.0234 - val_semantic_2_loss: 0.0025 - lr: 3.6973e-05\n"
     ]
    }
   ],
   "source": [
    "# fit again with K data\n",
    "\n",
    "loss_history = model.fit(\n",
    "    train_cd3,\n",
    "    steps_per_epoch=train_cd3.y.shape[0] // batch_size,\n",
    "    epochs=100,\n",
    "    validation_data=val_cd3,\n",
    "    validation_steps=val_cd3.y.shape[0] // batch_size,\n",
    "    callbacks=train_callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
